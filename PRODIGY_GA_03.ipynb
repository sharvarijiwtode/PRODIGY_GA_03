{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWcC1uiA9bwF41QV0C7WvX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharvarijiwtode/PRODIGY_GA_03/blob/main/PRODIGY_GA_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class MarkovChain:\n",
        "    def __init__(self, order=1):\n",
        "        self.order = order\n",
        "        self.lookup_dict = {}\n",
        "\n",
        "    def fit(self, text):\n",
        "        for i in range(len(text) - self.order):\n",
        "            current_state = text[i:i+self.order]\n",
        "            next_char = text[i+self.order]\n",
        "            if current_state not in self.lookup_dict:\n",
        "                self.lookup_dict[current_state] = []\n",
        "            self.lookup_dict[current_state].append(next_char)\n",
        "\n",
        "    def generate(self, start_text, num_chars):\n",
        "        if len(start_text) < self.order or start_text[:self.order] not in self.lookup_dict:\n",
        "             print(f\"Warning: Start text '{start_text}' is too short or not found in the training data. Using a random start.\")\n",
        "             start_text = random.choice(list(self.lookup_dict.keys()))\n",
        "\n",
        "        generated_text = start_text\n",
        "        current_state = start_text[-self.order:]\n",
        "\n",
        "        for _ in range(num_chars):\n",
        "            if current_state in self.lookup_dict:\n",
        "                next_char_candidates = self.lookup_dict[current_state]\n",
        "                next_char = random.choice(next_char_candidates)\n",
        "                generated_text += next_char\n",
        "                current_state = generated_text[-self.order:]\n",
        "            else:\n",
        "                break\n",
        "        return generated_text\n",
        "\n",
        "training_text = \"This is a simple example of a Markov chain text generator. Markov chains are statistical models.\"\n",
        "\n",
        "mc = MarkovChain(order=2)\n",
        "\n",
        "mc.fit(training_text)\n",
        "\n",
        "generated_text = mc.generate(start_text=\"Th\", num_chars=50)\n",
        "print(generated_text)\n",
        "\n",
        "generated_text_2 = mc.generate(start_text=\"text\", num_chars=100)\n",
        "generated_text_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "yC90Rppx1x7o",
        "outputId": "cc2644e5-8a35-4053-a3ef-b44ddaa12891"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is is is a Mare of a Markov chains is a Mare st\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'text generator. Mare of a stator. Mare ext generatis a Markov chains a Mare stistical models.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    }
  ]
}